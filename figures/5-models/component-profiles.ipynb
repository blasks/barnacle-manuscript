{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from functools import reduce\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from ncistd import plot_factors_heatmap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import string\n",
    "import tensorly as tl\n",
    "from tensorly.cp_tensor import CPTensor\n",
    "import tlviz\n",
    "from tlviz.factor_tools import factor_match_score\n",
    "from tlab.cp_tensor import load_cp_tensor\n",
    "import xarray as xr\n",
    "from ncistd.tensors import SparseCPTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aesthetic parameters\n",
    "\n",
    "line_color = '#0F0A0A'    # dark\n",
    "# line_color = '#E5E4E2'    # light\n",
    "\n",
    "neutral_color = '#E0E0E0'\n",
    "\n",
    "# thursday\n",
    "accent_colors = ['#9B5DE5', '#FFAC69', '#00C9AE', '#FD3F92', '#0F0A0A', \n",
    "                 '#959AB1', '#FFDB66', '#63B9FF','#FFB1CA', '#4F1DD7']\n",
    "\n",
    "style = {'axes.edgecolor': line_color,\n",
    "         'axes.labelcolor': line_color,\n",
    "         'text.color': line_color,\n",
    "         'xtick.color': line_color,\n",
    "         'ytick.color': line_color,\n",
    "         'font.family': 'Helvetica',\n",
    "         'font.Helvetica': ['Helvetica']}\n",
    "\n",
    "palette = sns.color_palette(accent_colors)\n",
    "\n",
    "sns.set_context('talk', rc={'lines.linewidth': 2})\n",
    "sns.set_palette(palette)\n",
    "# sns.set_palette('tab20')\n",
    "sns.set_style('ticks', style)\n",
    "\n",
    "plt.rcParams['legend.frameon'] = False\n",
    "plt.rcParams['axes.spines.left'] = True\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.bottom'] = True\n",
    "plt.rcParams['axes.facecolor'] = 'none'\n",
    "plt.rcParams['figure.facecolor'] = 'none'\n",
    "plt.rcParams['patch.linewidth'] = 0\n",
    "plt.rcParams['patch.edgecolor'] = 'none'\n",
    "plt.rcParams['savefig.dpi'] = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful functions\n",
    "    \n",
    "# function to select subset of indices in cp tensor\n",
    "def subset_cp_tensor(cp_tensor, subset_indices):\n",
    "    '''Selects subset of cp_tensor based on provided indices\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cp_tensor : tensorly.CPTensor\n",
    "        CPTensor object with (weights, factors).\n",
    "    subset_indices : dict(int: index-like)\n",
    "        Dictionary with mode as key and value an integer index of \n",
    "        the positions to be downselected from `cp_tensor`.\n",
    "        Example: {1: [0, 1, 3, 4, 5, 8]}\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    subset_cp : tensorly.CPTensor\n",
    "        Subset CPTensor.\n",
    "    '''\n",
    "    weights, factors = cp_tensor\n",
    "    new_factors = factors.copy()\n",
    "    for mode, index in subset_indices.items():\n",
    "        new_factors[mode] = factors[mode][index]\n",
    "    return(CPTensor((weights, new_factors)))\n",
    "\n",
    "# unique bin function\n",
    "def unique_bins(array, n_bins, bounds=None, reverse=False):\n",
    "    '''This is a function that maps an array of continuous values with potential duplicates to \n",
    "    a set of bins in such a way that each of the original continuous values is mapped to a unique bin, and the\n",
    "    distribution of binned values approximates the distribution of continuous values as closely as possible.\n",
    "    \n",
    "    My quick and dirty approach to this problem sorts the input array into the appropriate number of bins. Then,\n",
    "    starting in the middle and alternating outward left and right, the algorithm checks to see if each bin has \n",
    "    more than one resident. If so, it will again alternate outward left and right from that position and allocate\n",
    "    the extra residents to the nearest free bins.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array : np.array\n",
    "        Sorted array of values to be placed into bins.\n",
    "    n_bins : int\n",
    "        Number of bins to use.\n",
    "    bounds : (float, float)\n",
    "        Upper and lower bounds to use for bin-mapping.\n",
    "    reverse : bool\n",
    "        Optional flag to reverse the index ordering of the output.\n",
    "    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    index : np.array\n",
    "        Indices indicating mapping of input values to bins, where index[i] indicates the index of the bin \n",
    "        mapping of input value array[i] (assuming input array is sorted).\n",
    "    '''\n",
    "    # check number of bins\n",
    "    if not n_bins >= len(array):\n",
    "        raise ValueError('The number of bins must be >= len(array).')\n",
    "    # add bounds if supplied\n",
    "    if bounds is not None:\n",
    "        array = np.concatenate((array, bounds))\n",
    "    # make histogram\n",
    "    counts, _ = np.histogram(array, bins=n_bins)\n",
    "    # remove bounds if added\n",
    "    if bounds is not None:\n",
    "        counts[0] -= 1\n",
    "        counts[-1] -= 1\n",
    "    # start from the middle\n",
    "    i = int(n_bins/2)\n",
    "    for j in range(n_bins):\n",
    "        # alternate left and right\n",
    "        if j % 2:\n",
    "            i -= j\n",
    "        else:\n",
    "            i += j\n",
    "        # resolve collisions\n",
    "        if counts[i] > 1:\n",
    "            # set new counter for exploring nearby positions\n",
    "            k = i\n",
    "            for l in range(2*n_bins):\n",
    "                # alternate left and right\n",
    "                if l % 2:\n",
    "                    k -= l\n",
    "                else:\n",
    "                    k += l\n",
    "                # check if we're still in range\n",
    "                if 0 <= k < n_bins:\n",
    "                    # check for an empty spot\n",
    "                    if counts[k] == 0:\n",
    "                        counts[k] = 1\n",
    "                        counts[i] -= 1\n",
    "                        # check if all collisions have been resolved yet\n",
    "                        if counts[i] == 1:\n",
    "                            break\n",
    "    # select indices of non-zero values\n",
    "    index = np.where(counts == 1)[0]\n",
    "    # reverse if requested\n",
    "    if reverse:\n",
    "        index = (n_bins - 1) - index\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import decompositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection\n",
    "\n",
    "genus = 'syn'\n",
    "rank = 30\n",
    "lamb = 32.\n",
    "bootstraps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "replicates = ['A', 'B', 'C']\n",
    "\n",
    "# determined in component-robustness.ipynb analysis\n",
    "best_reps = {\n",
    "    'pro': {'rank': 30, 'lambda': 16., 'boot': 8, 'rep': 'C'}, \n",
    "    'syn': {'rank': 30, 'lambda': 16., 'boot': 0, 'rep': 'A'}\n",
    "}\n",
    "\n",
    "datapath = Path('../../data/4-fitting/{}/'.format(genus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch samplename labels for each shuffled replicate set\n",
    "\n",
    "# collect sample names of each bootstrap/replicate pair\n",
    "samplenames = {}\n",
    "for boot in bootstraps:\n",
    "    samplenames[boot] = {}\n",
    "    for rep in replicates:\n",
    "        ds = xr.open_dataset(datapath / 'bootstrap{}/replicate{}/shuffled_replicate_{}.nc'.format(boot, rep, rep))\n",
    "        samplenames[boot][rep] = ds.samplename.data\n",
    "\n",
    "# collect common samplenames (present in each bootstrap)\n",
    "samplenames['common'] = reduce(\n",
    "    np.intersect1d, \n",
    "    [samplenames[b][r] for b, r in list(itertools.product(bootstraps, replicates))]\n",
    ")\n",
    "\n",
    "tensor_ds = xr.open_dataset(datapath / 'bootstrap{}/dataset_bootstrap_{}.nc'.format(bootstraps[0], bootstraps[0]))\n",
    "\n",
    "tensor_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitted models\n",
    "\n",
    "cps = {}    # model as saved on computer\n",
    "aligned_cps = {}    # aligned to best representative, all samples present\n",
    "subset_aligned_cps = {}    # aligned to best representative, subset to just common samples\n",
    "\n",
    "# read in best representative reference cp\n",
    "path_ref_cp = 'bootstrap{}/replicate{}/rank{}/lambda{}/fitted_model.h5'.format(\n",
    "    best_reps[genus]['boot'], best_reps[genus]['rep'], best_reps[genus]['rank'], best_reps[genus]['lambda']\n",
    ")\n",
    "cps['ref'] = tl.cp_normalize(load_cp_tensor(datapath / path_ref_cp))\n",
    "# subset ref cp to common samplenames\n",
    "idx = np.where(np.isin(\n",
    "    samplenames[best_reps[genus]['boot']][best_reps[genus]['rep']], samplenames['common']\n",
    "))[0]\n",
    "subset_aligned_cps['ref'] = subset_cp_tensor(cps['ref'], {2: idx})\n",
    "# arrange components in descending order of explained variance\n",
    "subset_aligned_cps['ref'] = tlviz.factor_tools.permute_cp_tensor(\n",
    "    subset_aligned_cps['ref'], \n",
    "    consider_weights=False\n",
    ")\n",
    "\n",
    "# read in the rest of the cp tensor models\n",
    "for boot in bootstraps:\n",
    "    cps[boot] = {}\n",
    "    aligned_cps[boot] = {}\n",
    "    subset_aligned_cps[boot] = {} \n",
    "    for rep in replicates:\n",
    "        path_cp = 'bootstrap{}/replicate{}/rank{}/lambda{}/fitted_model.h5'.format(\n",
    "            boot, rep, rank, lamb\n",
    "        )\n",
    "        # store normalized cp tensor to cps\n",
    "        cps[boot][rep] = tl.cp_normalize(load_cp_tensor(datapath / path_cp))\n",
    "        # pull out aligned cps\n",
    "        idx = np.where(np.isin(samplenames[boot][rep], samplenames['common']))[0]\n",
    "        subset_aligned_cps[boot][rep] = subset_cp_tensor(cps[boot][rep], {2: idx})\n",
    "        # permute components to line up with best representative reference cp\n",
    "        perm = tlviz.factor_tools.get_cp_permutation(\n",
    "            subset_aligned_cps[boot][rep], \n",
    "            reference_cp_tensor=subset_aligned_cps['ref'], \n",
    "            consider_weights=False\n",
    "        )\n",
    "        subset_aligned_cps[boot][rep] = tlviz.factor_tools.permute_cp_tensor(\n",
    "            subset_aligned_cps[boot][rep], \n",
    "            permutation=perm\n",
    "        )\n",
    "        aligned_cps[boot][rep] = tlviz.factor_tools.permute_cp_tensor(\n",
    "            cps[boot][rep], \n",
    "            permutation=perm\n",
    "        )\n",
    "\n",
    "print(cps[0]['A'])\n",
    "print(aligned_cps[0]['A'])\n",
    "print(subset_aligned_cps[0]['A'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample metadata data\n",
    "\n",
    "filepath_metadata_sample = '../../data/metadata/sample_metadata_merged.csv'\n",
    "\n",
    "metadata_sample_df = pd.read_csv(filepath_metadata_sample).fillna('')\n",
    "\n",
    "metadata_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregate weights across bootstraps for each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters of the component we're looking at\n",
    "\n",
    "genus = 'syn'\n",
    "rank = 30\n",
    "lamb = 32.\n",
    "cluster = 5\n",
    "\n",
    "# arrange gene data\n",
    "labels = tensor_ds.ortholog.data\n",
    "annotations = tensor_ds.annotation.data\n",
    "annotation_dict = dict(zip(labels, annotations))\n",
    "data = []\n",
    "for boot in bootstraps:\n",
    "    for rep in replicates:\n",
    "        cp = aligned_cps[boot][rep]\n",
    "        weights = SparseCPTensor(cp).get_components()[cluster-1].factors[0].flatten()\n",
    "        support = (weights != 0)\n",
    "        data.append({\n",
    "            'bootstrap': boot, \n",
    "            'replicate': rep, \n",
    "            **dict(zip(labels[support], weights[support]))\n",
    "        })\n",
    "gene_df = pd.DataFrame(data).melt(id_vars=['bootstrap', 'replicate'], var_name='cycog', value_name='weight')\n",
    "counts = gene_df.groupby('cycog').weight.count()\n",
    "gene_df['% bootstraps'] = gene_df['cycog'].map(counts) / (len(bootstraps) * len(replicates))\n",
    "gene_df['annotation'] = gene_df['cycog'].map(annotation_dict)\n",
    "\n",
    "# arrange taxon data\n",
    "labels = [l if l != 'CDR2' else 'CRD2' for l in tensor_ds.clade.data]    # fix CRD2\n",
    "data = []\n",
    "for boot in bootstraps:\n",
    "    for rep in replicates:\n",
    "        cp = aligned_cps[boot][rep]\n",
    "        weights = SparseCPTensor(cp).get_components()[cluster-1].factors[1].flatten()\n",
    "        data.append({\n",
    "            'bootstrap': boot, \n",
    "            'replicate': rep, \n",
    "            **dict(zip(labels, weights))\n",
    "        })\n",
    "taxon_df = pd.DataFrame(data).melt(id_vars=['bootstrap', 'replicate'], var_name='ecotype', value_name='weight')\n",
    "\n",
    "# arrange sample data\n",
    "data = []\n",
    "for boot in bootstraps:\n",
    "    for rep in replicates:\n",
    "        labels = samplenames[boot][rep]\n",
    "        cp = aligned_cps[boot][rep]\n",
    "        weights = SparseCPTensor(cp).get_components()[cluster-1].factors[2].flatten()\n",
    "        data.append({\n",
    "            'bootstrap': boot, \n",
    "            'replicate': rep, \n",
    "            **dict(zip(labels, weights))\n",
    "        })\n",
    "sample_df = pd.DataFrame(data).melt(id_vars=['bootstrap', 'replicate'], var_name='samplename', value_name='weight')\n",
    "sample_df = pd.merge(left=sample_df, right=metadata_sample_df, on='samplename', how='left')\n",
    "\n",
    "gene_df.groupby('cycog')['% bootstraps'].mean().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecotype figure\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(5, 2))\n",
    "\n",
    "sns.stripplot(\n",
    "    data=taxon_df, \n",
    "    x='ecotype', \n",
    "    y='weight', \n",
    "    color=line_color, \n",
    "    alpha=.3, \n",
    "    size=7, \n",
    "    jitter=.2, \n",
    "    ax=axis\n",
    ")\n",
    "sns.barplot(\n",
    "    data=taxon_df, \n",
    "    x='ecotype', \n",
    "    y='weight', \n",
    "    color=sns.color_palette()[2], \n",
    "    errorbar=None, \n",
    "    ax=axis\n",
    ")\n",
    "axis.set(ylim=[-0.05, 1.05])\n",
    "axis.tick_params(axis='x', labelrotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gene figure\n",
    "\n",
    "thold_bootstrap = 0.5\n",
    "max_genes = 20\n",
    "\n",
    "plot_df = gene_df[gene_df['% bootstraps'].ge(thold_bootstrap)]\n",
    "# fill in nas\n",
    "plot_df = plot_df.fillna(0.0)\n",
    "# find top genes by mean weight\n",
    "top_genes = plot_df.groupby('cycog').weight.mean().sort_values(ascending=False).head(max_genes).index\n",
    "plot_df = plot_df[plot_df['cycog'].isin(top_genes)].reset_index()\n",
    "# sort by mean weight\n",
    "gene_labels = list(string.ascii_uppercase)[:max_genes]\n",
    "plot_df['gene'] = plot_df['cycog'].map(dict(zip(top_genes, gene_labels)))\n",
    "plot_df = plot_df.sort_values('gene')\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(12, 3))\n",
    "sns.stripplot(\n",
    "    data=plot_df, \n",
    "    x='gene', \n",
    "    y='weight', \n",
    "    color=line_color, \n",
    "    alpha=.3, \n",
    "    size=7, \n",
    "    jitter=.2, \n",
    "    ax=axis\n",
    ")\n",
    "sns.barplot(\n",
    "    data=plot_df, \n",
    "    x='gene', \n",
    "    y='weight', \n",
    "    color=sns.color_palette()[0], \n",
    "    errorbar=None, \n",
    "    ax=axis\n",
    ")\n",
    "axis.set(ylim=[-0.05, 1.05])\n",
    "\n",
    "# print the plot\n",
    "plt.show()\n",
    "\n",
    "# show gene name key\n",
    "gene_key_df = gene_df.fillna(0.0).groupby(['cycog', 'annotation'])[['weight', '% bootstraps']].mean().reset_index()\n",
    "gene_key_df['gene'] = gene_key_df['cycog'].map(dict(zip(top_genes, gene_labels)))\n",
    "gene_key_df = gene_key_df[\n",
    "    ['gene', 'cycog', 'annotation', 'weight', '% bootstraps']\n",
    "].sort_values('weight', ascending=False).sort_values('gene').reset_index(drop=True).fillna('')\n",
    "\n",
    "gene_key_df.to_csv('cluster{}.csv'.format(cluster), index=False)\n",
    "gene_key_df.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper plotting functions\n",
    "\n",
    "# def plot_weights(df, x, y, hue, axis):\n",
    "#     sns.barplot(\n",
    "#         data=plot_df, \n",
    "#         x='weight', \n",
    "#         y='lat_idx', \n",
    "#         color=sns.color_palette()[2], \n",
    "#         orient='h', \n",
    "#         order=np.arange(n_bins), \n",
    "#         ax=axis\n",
    "#     )\n",
    "#     sns.stripplot(\n",
    "#         data=plot_df, \n",
    "#         x='weight', \n",
    "#         y='lat_idx', \n",
    "#         color=line_color, \n",
    "#         alpha=.3, \n",
    "#         size=5, \n",
    "#         jitter=.2, \n",
    "#         orient='h', \n",
    "#         order=np.arange(n_bins), \n",
    "#         ax=axis\n",
    "#     )\n",
    "    \n",
    "incubation_treatment_order = {\n",
    "    'HNLC': ['control 0h', 'control 2h', 'control 96h', 'low Fe', 'high Fe', 'N+P+Fe', 'DHPS', 'isethionate', 'taurine'], \n",
    "    'TZ': ['control 0h', 'control 2h', 'control 96h', 'Fe', 'N+P', 'N+P+Fe', 'DHPS', 'isethionate', 'taurine'], \n",
    "    'gyre': ['control 0h', 'control 2h', 'control 96h', 'low N+P', 'high N+P', 'N+P+Fe', 'DHPS', 'isethionate', 'taurine']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample figure\n",
    "\n",
    "# figure specs\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "rows = 3\n",
    "cols = 9\n",
    "grid = plt.GridSpec(rows, cols, wspace=.2, hspace=.3)\n",
    "annot_kwgs = {\n",
    "    'xycoords': 'axes fraction', 'va': 'center', 'ha': 'left', 'fontsize': 22, 'annotation_clip': False\n",
    "}\n",
    "\n",
    "# latitude binning specs\n",
    "n_bins = 21\n",
    "bounds = (23, 43)\n",
    "\n",
    "# plot surface transect data\n",
    "for i, year in enumerate([2016, 2017, 2019]):\n",
    "    axis = plt.subplot(grid[0:rows, i])\n",
    "    # ax_a.annotate('A', xy=(-0.2, 1.15), **annot_kwgs)\n",
    "    # get data together\n",
    "    plot_df = sample_df[sample_df['samplegroup'] == 'surface transect']\n",
    "    plot_df = plot_df[plot_df['year'] == year]\n",
    "    latitudes = plot_df[\n",
    "        ['samplename', 'latitude']].drop_duplicates().set_index('samplename').sort_values('latitude')['latitude']\n",
    "    lat_bins = unique_bins(latitudes, n_bins, bounds=bounds, reverse=True)\n",
    "    plot_df['lat_idx'] = plot_df['samplename'].map(dict(zip(latitudes.index, lat_bins)))\n",
    "    # make figure\n",
    "    sns.barplot(\n",
    "        data=plot_df, \n",
    "        x='weight', \n",
    "        y='lat_idx', \n",
    "        color=sns.color_palette()[2], \n",
    "#         hue='timefraction', \n",
    "#         palette='cubehelix', \n",
    "        orient='h', \n",
    "        order=np.arange(n_bins), \n",
    "        ax=axis\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=plot_df, \n",
    "        x='weight', \n",
    "        y='lat_idx', \n",
    "        color=line_color, \n",
    "        alpha=.3, \n",
    "        size=5, \n",
    "        jitter=.2, \n",
    "        orient='h', \n",
    "        order=np.arange(n_bins), \n",
    "        ax=axis\n",
    "    )\n",
    "    # set labels and such\n",
    "#     axis.set(xlim=[-0.05, 1.05], ylabel='', xlabel=('' if i != 1 else 'weight'))\n",
    "    axis.set(xlim=[-0.05, 1.05], ylabel='', xlabel='weight')\n",
    "    if not i:\n",
    "        axis.set_yticks(np.arange(n_bins), [f'{int(l)}N' for l in np.linspace(bounds[1], bounds[0], num=n_bins)])\n",
    "    else:\n",
    "        axis.tick_params(left=True, labelleft=False)\n",
    "\n",
    "# plot diel data\n",
    "axis = plt.subplot(grid[0:rows, 4])\n",
    "# axis.annotate('B', xy=(-0.2, 1.15), **annot_kwgs)\n",
    "# get data together\n",
    "plot_df = sample_df[sample_df['samplegroup'] == 'diel study'].sort_values('datetime')\n",
    "n_samples = plot_df['samplename'].nunique()\n",
    "plot_df['idx'] = plot_df['samplename'].map(dict(zip(plot_df['samplename'].unique(), np.arange(n_samples))))\n",
    "sns.barplot(\n",
    "    data=plot_df, \n",
    "    x='weight', \n",
    "    y='idx', \n",
    "    color=sns.color_palette()[2], \n",
    "    orient='h', \n",
    "    ax=axis\n",
    ")\n",
    "sns.stripplot(\n",
    "    data=plot_df, \n",
    "    x='weight', \n",
    "    y='idx', \n",
    "    color=line_color, \n",
    "    alpha=.3, \n",
    "    size=5, \n",
    "    jitter=.2, \n",
    "    orient='h', \n",
    "    ax=axis\n",
    ")\n",
    "axis.set(xlim=[-0.05, 1.05], ylabel='')\n",
    "axis.set_yticks(np.arange(n_samples), plot_df[['samplename', 'timeclass']].drop_duplicates()['timeclass']);\n",
    "\n",
    "# plot depth data\n",
    "axis = plt.subplot(grid[0:rows, 6])\n",
    "# axis.annotate('B', xy=(-0.2, 1.15), **annot_kwgs)\n",
    "# get data together\n",
    "plot_df = sample_df[sample_df['samplegroup'] == 'depth profiles'].sort_values(\n",
    "    ['latitude', 'depth'], ascending=[False, True])\n",
    "n_samples = plot_df['samplename'].nunique()\n",
    "plot_df['idx'] = plot_df['samplename'].map(dict(zip(plot_df['samplename'].unique(), np.arange(n_samples))))\n",
    "sns.barplot(\n",
    "    data=plot_df, \n",
    "    x='weight', \n",
    "    y='idx', \n",
    "    color=sns.color_palette()[2], \n",
    "    orient='h', \n",
    "    ax=axis\n",
    ")\n",
    "sns.stripplot(\n",
    "    data=plot_df, \n",
    "    x='weight', \n",
    "    y='idx', \n",
    "    color=line_color, \n",
    "    alpha=.3, \n",
    "    size=5, \n",
    "    jitter=.2, \n",
    "    orient='h', \n",
    "    ax=axis\n",
    ")\n",
    "axis.set(xlim=[-0.05, 1.05], ylabel='')\n",
    "label_df = plot_df[['samplename', 'depth', 'latitude']].drop_duplicates()\n",
    "labels = [f'{int(r[2])}N,{r[1]:4}m' for _, r in label_df.iterrows()]\n",
    "axis.set_yticks(np.arange(n_samples), labels);\n",
    "\n",
    "# plot incubation data\n",
    "for i, condition in enumerate(['HNLC', 'TZ', 'gyre']):\n",
    "    axis = plt.subplot(grid[i, 8])\n",
    "    # axis.annotate('B', xy=(-0.2, 1.15), **annot_kwgs)\n",
    "    # get data together\n",
    "    plot_df = sample_df[sample_df['condition'] == condition]\n",
    "    sns.barplot(\n",
    "        data=plot_df, \n",
    "        x='weight', \n",
    "        y='treatment', \n",
    "        order=incubation_treatment_order[condition], \n",
    "        color=sns.color_palette()[2], \n",
    "        orient='h', \n",
    "        ax=axis\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=plot_df, \n",
    "        x='weight', \n",
    "        y='treatment', \n",
    "        order=incubation_treatment_order[condition], \n",
    "        color=line_color, \n",
    "        alpha=.3, \n",
    "        size=5, \n",
    "        jitter=.2, \n",
    "        orient='h', \n",
    "        ax=axis\n",
    "    )\n",
    "    axis.set(xlim=[-0.05, 1.05], ylabel='', xlabel=('weight' if i == 2 else ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
